/* eslint-disable no-console */
require('dotenv').config();
const fs = require('fs');
const { OpenAI } = require('openai');
const path = require('path');
const aiPrompt = require('./ai-prompt');

async function analyzeBenchmark({
  language = '‰∏≠Êñá',
  techStack = 'nodejs',
  model = 'gpt-4o',
  benchmarkRawFilePath,
} = {}) {
  const openai = new OpenAI({ apiKey: process.env.OPENAI_CLIENT, baseURL: process.env.OPENAI_BASE_URL });

  if (!fs.existsSync(benchmarkRawFilePath)) {
    console.error('‚ùå benchmark.log not found');
    return;
  }

  const logContent = fs.readFileSync(benchmarkRawFilePath, 'utf-8');

  // Êà™Êñ≠‰ª•Èò≤Ë∂ÖËøá token ÈôêÂà∂
  const maxChars = 40000;
  const promptText =
    logContent.length > maxChars ? logContent.slice(logContent.length - maxChars, logContent.length) : logContent;

  const prompt = aiPrompt(techStack, language, promptText);

  console.log('üß† Ask OpenAI for analysis...');

  try {
    const completion = await openai.chat.completions.create({
      model,
      messages: [
        {
          role: 'user',
          content: prompt,
        },
      ],
      temperature: 0.3,
    });

    const reply = completion.choices[0].message.content;
    console.log('\n‚úÖ Analysis report:\n');
    console.log(reply);
    fs.writeFileSync(path.join(process.cwd(), 'benchmark-output', 'README.md'), reply);
  } catch (err) {
    console.error('‚ùå OpenAI request failed:', err.message);
  }
}

module.exports = analyzeBenchmark;
